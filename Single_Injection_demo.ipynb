{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import QhX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46172b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QhX.data_manager import DataManager\n",
    "data_manager = DataManager()\n",
    "fs_df = data_manager.load_fs_df('https://zenodo.org/record/6878414/files/ForcedSourceTable.parquet')\n",
    "fs_gp = data_manager.group_fs_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_objects=data_manager.load_object_df(\"https://zenodo.org/record/6878414/files/ObjectTable.parquet\")\n",
    "#Find quasars IDs\n",
    "setindexqso=td_objects[(td_objects[\"class\"].eq(\"Qso\"))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b884592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e039c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "##FIND quasars indices and transform to arrays\n",
    "setindexnew=data_manager.get_qso(setindexqso)\n",
    "setindexnew=np.array(setindexnew)\n",
    "df = pd.DataFrame({'objectId': setindexnew})\n",
    "df.set_index('objectId', inplace=True)\n",
    "setidnew=df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b51fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QhX.light_curve import get_lctiktok, get_lc22\n",
    "light_curves_data = get_lc22(data_manager, '1384142', include_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896612e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QhX.calculation import *\n",
    "from QhX.detection import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure to import or define other necessary functions like hybrid2d, periods, same_periods, etc.\n",
    "from QhX.algorithms.wavelets.wwtz import *\n",
    "process1_results = process1_new(data_manager, '1384142', ntau=80, ngrid=800, provided_minfq=2000, provided_maxfq=10, include_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d9ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QhX.output import classify_periods, classify_period\n",
    "outt=classify_periods([process1_results])\n",
    "outt['classification'] =outt.apply(classify_period, axis=1)\n",
    "print(outt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66128372",
   "metadata": {},
   "outputs": [],
   "source": [
    "outt['classification'] =outt.apply(classify_period, axis=1)\n",
    "print(outt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_sinusoid(time, amplitude, period):\n",
    "    \"\"\"\n",
    "    Generate a sinusoidal signal.\n",
    "\n",
    "    :param time: Array of time points at which to evaluate the sinusoid.\n",
    "    :param amplitude: Amplitude of the sinusoid.\n",
    "    :param period: Period of the sinusoid.\n",
    "    :return: Array of sinusoidal values.\n",
    "    \"\"\"\n",
    "    return amplitude * np.sin(2 * np.pi * time / period)\n",
    "\n",
    "def inject_sinus(time, light_curve, period,amplitude_percentage):\n",
    "    \"\"\"\n",
    "    Inject a sinusoidal signal into a quasar red noise light curve.\n",
    "\n",
    "    :param light_curve: Original quasar red noise light curve.\n",
    "    :param time: Array of time points corresponding to the light curve data.\n",
    "    :param amplitude_percentage: Percentage of the light curve's amplitude to use for the sinusoid.\n",
    "    :param period: Period of the sinusoidal signal to inject.\n",
    "    :return: Light curve with the sinusoidal signal injected.\n",
    "    \"\"\"\n",
    "    max_amplitude = np.max(light_curve) - np.min(light_curve)\n",
    "    sinusoid_amplitude = max_amplitude * amplitude_percentage / 100\n",
    "    sinusoid = generate_sinusoid(time, sinusoid_amplitude, period)\n",
    "    return light_curve + sinusoid,time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3cc737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sinus(data_manager, set1, period, amplitude_percentage):\n",
    "    \"\"\"\n",
    "    Processes light curve data and optionally injects a tik-tok signal based on specified parameters.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "     - set1: Identifier for the dataset to process.\n",
    "     - period (float): Period of the  signal.\n",
    "     - amplitude_percentage (float): Percentage of the light curve's amplitude to use for the sinusoid.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: Processed time and magnitude data for multiple filters, their sampling rates, and tik-tok signals if injected.\n",
    "    \"\"\"\n",
    "    if set1 not in fs_gp.groups:\n",
    "        print(f\"Set ID {set1} not found.\")\n",
    "        return None\n",
    "       # Retrieve the light curve data for the specified set\n",
    "    # Retrieve and process the light curve data for the specified set\n",
    "    demo_lc = fs_gp.get_group(set1)\n",
    " \n",
    "    # Process the data for each filter, sort by MJD, drop rows where MJD is 0 or NaN\n",
    "    d0, d1, d2, d3 = [\n",
    "        demo_lc[(demo_lc['filter'] == f) & (demo_lc['mjd'] != 0)].sort_values(by=['mjd']).dropna()\n",
    "        for f in range(1, 5)\n",
    "    ]\n",
    "    # Convert the MJD and magnitude data to numpy arrays for each filter\n",
    "    tt00, yy00 = d0['mjd'].to_numpy(), d0['psMag'].to_numpy()\n",
    "    tt11, yy11 = d1['mjd'].to_numpy(), d1['psMag'].to_numpy()\n",
    "    tt22, yy22 = d2['mjd'].to_numpy(), d2['psMag'].to_numpy()\n",
    "    tt33, yy33 = d3['mjd'].to_numpy(), d3['psMag'].to_numpy()\n",
    "\n",
    "    # Remove outliers from each dataset\n",
    "   # tt0, yy0 = outliers(tt00, yy00)\n",
    "   # tt1, yy1 = outliers(tt11, yy11)\n",
    "   # tt2, yy2 = outliers(tt22, yy22)\n",
    "   # tt3, yy3 = outliers(tt33, yy33)\n",
    "\n",
    "    # Calculate the mean sampling rate for each dataset\n",
    "    sampling0, sampling1, sampling2, sampling3 = [np.mean(np.diff(tt)) for tt in [tt00, tt11, tt22, tt33]]\n",
    "\n",
    "    # Inject the tik-tok signal into the light curve data if specified\n",
    "    yy0, tik0 = inject_sinus(tt00, yy00, period, amplitude_percentage)\n",
    "    yy1, tik1 = inject_sinus(tt11, yy11, period,amplitude_percentage)\n",
    "    yy2, tik2 = inject_sinus(tt22, yy22, period, amplitude_percentage)\n",
    "    yy3, tik3 = inject_sinus(tt33, yy33, period, amplitude_percentage)\n",
    "\n",
    "    # Return the processed data\n",
    "    return tt00, yy0, tt11, yy1, tt22, yy2, tt33, yy3, sampling0, sampling1, sampling2, sampling3, tik0, tik1, tik2, tik3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt0, yy0, tt1, yy1, tt2, yy2, tt3, yy3, sampling0, sampling1, sampling2, sampling3, tik0, tik1, tik2, tik3=get_sinus(fs_gp, '1384142', 50,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48489aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling0,sampling1,sampling2,sampling3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba042101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55859929",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tt0,yy0,'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ffd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QhX.algorithms.wavelets.wwtz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1766a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        self.fs_df = None\n",
    "        self.fs_gp = None\n",
    "        self.object_df = None\n",
    "        self.td_objects = None\n",
    "\n",
    "    def load_fs_df(self, path_source: str, format: str = 'parquet') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data from a file with support for multiple formats.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path_source : str\n",
    "            The path to the data file.\n",
    "        format : str, optional\n",
    "            The format of the file (default is 'parquet').\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame or None\n",
    "            The loaded DataFrame or None in case of an error.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if format == 'parquet':\n",
    "                df = pd.read_parquet(path_source)\n",
    "            elif format == 'csv':\n",
    "                df = pd.read_csv(path_source)\n",
    "            else:\n",
    "                logging.error(f\"Unsupported file format: {format}\")\n",
    "                return None\n",
    "            logging.info(f\"Data loaded successfully from {path_source}.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def group_fs_df(self, df: pd.DataFrame, group_by: str) -> pd.core.groupby.DataFrameGroupBy:\n",
    "        \"\"\"\n",
    "        Group data by a specified column.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            The DataFrame to group.\n",
    "        group_by : str\n",
    "            The column name to group by.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.core.groupby.DataFrameGroupBy or None\n",
    "            The grouped DataFrame or None if the DataFrame is not available.\n",
    "        \"\"\"\n",
    "        if df is not None:\n",
    "            grouped = df.groupby(group_by)\n",
    "            logging.info(\"Data grouped successfully.\")\n",
    "            return grouped\n",
    "        else:\n",
    "            logging.warning(\"DataFrame is not available for grouping.\")\n",
    "            return None\n",
    "\n",
    "    def get_qso(self, grouped_data: pd.core.groupby.DataFrameGroupBy, object_ids: list, min_points: int = 100, filters: list = None) -> list:\n",
    "        \"\"\"\n",
    "        Get QSOs with complete light curves for specified filters with at least 'min_points' points.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        grouped_data : pd.core.groupby.DataFrameGroupBy\n",
    "            The grouped DataFrame.\n",
    "        object_ids : list\n",
    "            List of object IDs to check.\n",
    "        min_points : int, optional\n",
    "            Minimum number of points required in each light curve (default is 100).\n",
    "        filters : list, optional\n",
    "            List of filters to check (default is None, which checks all filters).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            List of QSO IDs that meet the criteria.\n",
    "        \"\"\"\n",
    "        valid_qsos = []\n",
    "        for obj_id in object_ids:\n",
    "            if obj_id in grouped_data.groups:\n",
    "                lc = grouped_data.get_group(obj_id)\n",
    "                if filters is None:\n",
    "                    filters = lc['filter'].unique()\n",
    "                if all(len(lc[lc['filter'] == f].dropna()) >= min_points for f in filters):\n",
    "                    valid_qsos.append(obj_id)\n",
    "        return valid_qsos\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8161ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "data_manager = DataManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manager.group_fs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QhX.data_manager import DataManager\n",
    "data_manager = DataManager()\n",
    "fs_df = data_manager.load_fs_df('https://zenodo.org/record/6878414/files/ForcedSourceTable.parquet')\n",
    "fs_gp = data_manager.group_fs_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b0d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_df = data_manager.load_fs_df('https://zenodo.org/record/6878414/files/ForcedSourceTable.parquet', format='parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94567f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fs_df is not None:\n",
    "    fs_gp = data_manager.group_fs_df(fs_df, 'objectId')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the object data from a Parquet file\n",
    "object_df = data_manager.load_fs_df(\"https://zenodo.org/record/6878414/files/ObjectTable.parquet\", format='parquet')\n",
    "\n",
    "# Check if the data is loaded and has the 'class' column\n",
    "if object_df is not None and 'class' in object_df.columns:\n",
    "    # Find quasars IDs\n",
    "    quasar_df = object_df[object_df['class'] == 'Qso']\n",
    "\n",
    "    # Get the indices or IDs of the quasars\n",
    "    quasar_ids = quasar_df.index.tolist()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf601f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "setindexqso =object_df[object_df[\"class\"] == \"Qso\"].index.tolist()\n",
    "\n",
    "# If additional filtering is needed (e.g., based on light curve data), you can use get_qso\n",
    "# For now, assuming setindexqso contains the IDs we need and we don't have to call get_qso\n",
    "# because get_qso method in the new DataManager needs grouped data and specific criteria\n",
    "\n",
    "# Convert the list of QSO IDs to a numpy array\n",
    "setindexnew = np.array(setindexqso)\n",
    "\n",
    "# Create a DataFrame with the quasar IDs\n",
    "df = pd.DataFrame({'objectId': setindexnew})\n",
    "\n",
    "# Set the 'objectId' column as the index of the DataFrame\n",
    "df.set_index('objectId', inplace=True)\n",
    "\n",
    "# Now df.index contains the quasar IDs as the DataFrame index\n",
    "setidnew = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31faa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lc_general(fs_df, object_id, include_errors=True):\n",
    "    \"\"\"\n",
    "    Process and return light curves with an option to include magnitude errors for a given object ID.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - data_manager (DataManager): The DataManager instance with loaded light curve data.\n",
    "    - object_id (str): The object ID for which light curves are to be processed.\n",
    "    - include_errors (bool, optional): Flag to include magnitude errors in the time series. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: Contains the processed time series with or without magnitude errors for each\n",
    "           filter, along with their respective sampling rates. Returns None if the object ID\n",
    "           is not found or if any filter data is missing.\n",
    "    \"\"\"\n",
    "    if fs_df is None or object_id not in fs_df['objectId'].unique():\n",
    "        print(f\"Object ID {object_id} not found.\")\n",
    "        return None\n",
    "\n",
    "    demo_lc = fs_df[fs_df['objectId'] == object_id]\n",
    "    if demo_lc.empty:\n",
    "        print(f\"No light curve data found for object ID {object_id}.\")\n",
    "        return None\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for filter_value in range(1, 5):  # Assuming filters range from 1 to 4\n",
    "        d = demo_lc[demo_lc['filter'] == filter_value].sort_values(by=['mjd']).dropna()\n",
    "        if d.empty or ('psMagErr' not in d.columns and include_errors):\n",
    "            print(f\"No data or 'err' column not found for filter {filter_value} for object ID {object_id}.\")\n",
    "            return None\n",
    "\n",
    "        tt, yy = d['mjd'].to_numpy(), d['psMag'].to_numpy()\n",
    "        err_mag = d['psMagErr'].to_numpy() if 'psMagErr' in d.columns and include_errors else None\n",
    "\n",
    "        # Apply any data cleaning or outlier removal here, if necessary\n",
    "        # For now, we assume a function `outliers_mad` exists for this purpose\n",
    "        # if include_errors and err_mag is not None:\n",
    "        #     tt, yy, err_mag = outliers_mad(tt, yy, err_mag)\n",
    "        # else:\n",
    "        #     tt, yy = outliers_mad(tt, yy)\n",
    "        yy,_= inject_sinus(tt, yy, 50, 0.2)\n",
    "        ts_with_or_without_errors = yy\n",
    "\n",
    "        if include_errors and err_mag is not None:\n",
    "            ts_with_or_without_errors = yy + np.random.normal(0, err_mag)\n",
    "\n",
    "        sampling_rate = np.mean(np.diff(tt)) if len(tt) > 1 else 0\n",
    "\n",
    "        results.extend([tt, ts_with_or_without_errors, sampling_rate])\n",
    "\n",
    "    return tuple(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Inject the tik-tok signal into the light curve data if specified\n",
    "    yy0, tik0 = inject_sinus(tt00, yy00, period, amplitude_percentage)\n",
    "    yy1, tik1 = inject_sinus(tt11, yy11, period,amplitude_percentage)\n",
    "    yy2, tik2 = inject_sinus(tt22, yy22, period, amplitude_percentage)\n",
    "    yy3, tik3 = inject_sinus(tt33, yy33, period, amplitude_percentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25289b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=get_lc_general(fs_df, '1384142', include_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    " tt0, yy0, sampling0, tt1, yy1,sampling1, tt2, yy2, sampling2, tt3, yy3,  sampling3 =results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ebbc29",
   "metadata": {},
   "source": [
    "sampling0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab33817",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling0,sampling1,sampling2,sampling3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd658533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process1_new(DataManager, set1, ntau=None, ngrid=None, provided_minfq=None, provided_maxfq=None, include_errors=True, parallel=False):\n",
    "    \"\"\"\n",
    "    Processes and analyzes light curve data from a single object to detect common periods across different bands.\n",
    "\n",
    "    The process involves:\n",
    "    \n",
    "    - Verifying the existence of the dataset.\n",
    "    - Retrieving and processing light curve data for different bands.\n",
    "    - Applying hybrid wavelet techniques to each band's light curve data.\n",
    "    - Comparing periods detected in different bands to find common periods, if they do not differ more than 10%.\n",
    "    - Compiling the results, including period values, errors, and significance, into a structured format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    set1 : int\n",
    "        An identifier representing the dataset to be processed.\n",
    "    ntau : int, optional\n",
    "        Number of time delays in the wavelet analysis.\n",
    "    ngrid : int, optional\n",
    "        Number of grid points in the wavelet analysis.\n",
    "    provided_minfq : float, optional\n",
    "        Period correspondig to the Minimum frequency for analysis, default is calculated from data.\n",
    "    provided_maxfq : float, optional\n",
    "        Period corresponding to the Maximum frequency for analysis, default is calculated from data.\n",
    "    include_errors : bool, optional\n",
    "        Include magnitude errors in analysis. Defaults to True.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    A list of dictionaries representing the results of the analysis performed on light curve data. Each dictionary contains:\n",
    "    \n",
    "        - objectid (int): Identifier of the object ID.\n",
    "        - sampling_i (float): Mean sampling rate in the first band of the pair where a common period is detected.\n",
    "        - sampling_j (float): Mean sampling rate in the second band in the pair.\n",
    "        - period (float): Detected common period between the two bands. NaN if no period is detected.\n",
    "        - upper_error (float): Upper error of the detected period. NaN if no period is detected.\n",
    "        - lower_error (float): Lower error of the detected period. NaN if no period is detected.\n",
    "        - significance (float): Measure of the statistical significance of the detected period. NaN if no period is detected.\n",
    "        - label (str): Label identifying the pair of bands where the period was detected (e.g., '0-1', '1-2').\n",
    "\n",
    "    Example Usage\n",
    "    -------------\n",
    "    # results = process1_new(data_manager, '1384142', ntau=80, ngrid=800, provided_minfq=2000, provided_maxfq=10, include_errors=False)\n",
    "    # df = pd.DataFrame(results)\n",
    "    # df.to_csv('light_curve_analysis.csv', index=False)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assume get_lc_general returns a tuple for each band: (time, magnitude, sampling_rate, errors)\n",
    "    light_curves_data = get_lc_general(DataManager, set1, include_errors)\n",
    "    print('a')\n",
    "    if light_curves_data is None:\n",
    "        print(f\"No data found for object ID {object_id}.\")\n",
    "        return None\n",
    "\n",
    "    tt0, yy0, sampling0, tt1, yy1,sampling1, tt2, yy2, sampling2, tt3, yy3,  sampling3 = light_curves_data\n",
    "    results = []\n",
    "    for tt, yy in [(tt0, yy0), (tt1, yy1), (tt2, yy2), (tt3, yy3)]:\n",
    "        wwz_matrix, corr, extent = hybrid2d(tt, yy, ntau=ntau, ngrid=ngrid, minfq=provided_minfq, maxfq=provided_maxfq, parallel=parallel)\n",
    "        peaks, hh, r_periods, up, low = periods(set1, corr, ngrid=ngrid, plot=False, minfq=provided_minfq, maxfq=provided_maxfq)\n",
    "        results.append((r_periods, up, low, peaks, hh))\n",
    "\n",
    "    sampling_rates = [sampling0, sampling1, sampling2, sampling3]\n",
    "    light_curve_labels = ['0', '1', '2', '3']\n",
    "\n",
    "    det_periods = []\n",
    "    for i in range(len(results)):\n",
    "        for j in range(i + 1, len(results)):\n",
    "            r_periods_i, up_i, low_i, peaks_i, hh_i = results[i]\n",
    "            r_periods_j, up_j, low_j, peaks_j, hh_j = results[j]\n",
    "\n",
    "            r_periods_common, u_common, low_common, sig_common = same_periods(\n",
    "                r_periods_i, r_periods_j, up_i, low_i, up_j, low_j, peaks_i, hh_i, tt0, yy0, peaks_j, hh_j, tt1, yy1,\n",
    "                ntau=ntau, ngrid=ngrid, minfq=provided_minfq, maxfq=provided_maxfq\n",
    "            )\n",
    "\n",
    "            if len(r_periods_common) == 0:\n",
    "                det_periods.append({\n",
    "                    \"objectid\": set1,\n",
    "                    \"sampling_i\": sampling_rates[i],\n",
    "                    \"sampling_j\": sampling_rates[j],\n",
    "                    \"period\": np.nan,\n",
    "                    \"upper_error\": np.nan,\n",
    "                    \"lower_error\": np.nan,\n",
    "                    \"significance\": np.nan,\n",
    "                    \"label\": f\"{light_curve_labels[i]}-{light_curve_labels[j]}\"\n",
    "                })\n",
    "            else:\n",
    "                for k in range(len(r_periods_common)):\n",
    "                    det_periods.append({\n",
    "                        \"objectid\": set1,\n",
    "                        \"sampling_i\": sampling_rates[i],\n",
    "                        \"sampling_j\": sampling_rates[j],\n",
    "                        \"period\": r_periods_common[k],\n",
    "                        \"upper_error\": u_common[k],\n",
    "                        \"lower_error\": low_common[k],\n",
    "                        \"significance\": sig_common[k],\n",
    "                        \"label\": f\"{light_curve_labels[i]}-{light_curve_labels[j]}\"\n",
    "                    })\n",
    "\n",
    "    return det_periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e82d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QhX.calculation import *\n",
    "from QhX.detection import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure to import or define other necessary functions like hybrid2d, periods, same_periods, etc.\n",
    "from QhX.algorithms.wavelets.wwtz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad64e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "process1_results = process1_new(fs_df, '1384142', ntau=80, ngrid=800, provided_minfq=2000, provided_maxfq=10, include_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da846595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QhX.output import classify_periods, classify_period\n",
    "outt=classify_periods([process1_results])\n",
    "outt['classification'] =outt.apply(classify_period, axis=1)\n",
    "print(outt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c125e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de826f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_curves_data = get_lc22(data_manager, '1384142', include_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03a0fb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_manager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_manager\u001b[49m\u001b[38;5;241m.\u001b[39mfs_gp\u001b[38;5;241m.\u001b[39mgroups\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_manager' is not defined"
     ]
    }
   ],
   "source": [
    "data_manager.fs_gp.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a1e0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
